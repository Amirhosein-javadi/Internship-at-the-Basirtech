# -*- coding: utf-8 -*-
"""plate_neural_network_two_layer.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-sVcbDw6l1ovJONqUtuIa1JPmZeGvJJA
"""

!git clone https://github.com/Amirhosein-javadi/internship-at-the-Basirtech.git

"""Imports"""

import tensorflow as tf
tf.config.experimental.set_memory_growth(tf.config.list_physical_devices('GPU')[0],True)
import numpy as np
from keras import initializers,Sequential
from keras.layers import Input, Dense, Activation,BatchNormalization, Flatten, Conv2D, MaxPooling2D
from keras.models import Model
from keras.preprocessing import image
from keras import metrics
from keras.metrics import SparseTopKCategoricalAccuracy 
import keras.backend as K
K.set_image_data_format("channels_last")
import glob 
import matplotlib.pyplot as plt
import cv2
from sklearn.decomposition import PCA
from keras.datasets import mnist
import random

"""Functions"""

def create_data(file):
  img = cv2.imread(file[0],0)
  data = np.zeros((1,img.size)).astype(np.float64)
  for i in range(len(file)):
    name = file[i]
    img = cv2.imread(name,0).astype(np.float64)
    reshaped_img = img.reshape((1,-1))
    data = cv2.vconcat([data,reshaped_img])
  data = np.delete(data, 0, 0)
  return data

def Create_data_label(fat,tall,car,dim,start,stop):
  New_data = cv2.vconcat([fat[start:stop,:],tall[start:stop,:],car[start:stop,:]])
  New_label = np.zeros((3*(stop-start),3))
  for i in range(stop-start):
    New_label[i,0] = 1
  for i in range(stop-start,2*(stop-start)):
    New_label[i,1] = 1
  for i in range(2*(stop-start),3*(stop-start)):
    New_label[i,2] = 1
  return New_data,New_label

"""Creating folder for images in drive"""

try:
  !rm -rf fat
  !mkdir fat
except:
  !mkdir fat

try:
  !rm -rf tall
  !mkdir tall
except:
  !mkdir tall

try:
  !rm -rf car
  !mkdir car
except:
  !mkdir car

"""Loading and resizing fat plates to size 30*60"""

Filenames1 = glob.glob('/content/internship-at-the-Basirtech/images/fat/*')
for i in range(len(Filenames1)):
    name1 = Filenames1[i]
    img1 = cv2.imread(name1)
    resize_im1 = cv2.resize(img1,(60,30),interpolation = cv2.INTER_AREA)
    new_name1 = f'/content/fat/{i}.jpg'
    cv2.imwrite(new_name1,resize_im1)

"""Loading and resizing tall plates to size 30*60"""

Filenames2 = glob.glob('/content/internship-at-the-Basirtech/images/tall/*')
for i in range(len(Filenames2)):
     name2 = Filenames2[i]
     img2 = cv2.imread(name2)
     resize_im2 = cv2.resize(img2,(60,30),interpolation = cv2.INTER_AREA)
     new_name2 = f'/content/tall/{i}.jpg'
     cv2.imwrite(new_name2,resize_im2)

"""Creating random images from car images"""

filename = glob.glob('/content/internship-at-the-Basirtech/images/car img/*')
k = 1
for i in range(len(filename)):
    name = filename[i]
    img = cv2.imread(name)
    row,col = img.shape[0],img.shape[1]
    for j in range(4):
        random_row = random.randint(100, row-100)
        random_col = random.randint(100, col-100)
        newimg = img[random_row-100:random_row+100,random_col-100:random_col+100]
        newimg = cv2.resize(newimg,(60,30),interpolation = cv2.INTER_AREA)
        new_name = f'car/{k}.jpg'
        cv2.imwrite(new_name,newimg)
        k = k + 1

"""Loading data"""

fat_plates_path = '/content/fat'
fat_image_file = glob.glob(f'{fat_plates_path}/*')
tall_plates_path = '/content/tall'
tall_image_file = glob.glob(f'{tall_plates_path}/*')
car_path = '/content/car'
car_image_file = glob.glob(f'{car_path}/*')

tall_data = create_data(tall_image_file)
fat_data = create_data(fat_image_file)
car_data = create_data(car_image_file)

"""normalizing data to 0 mean and 1 std"""

for i in range(len(tall_data)):
  tall_data[i] = (tall_data[i]-np.mean(tall_data[i]))/np.std(tall_data[i])
for i in range(len(fat_data)):
  fat_data[i] = (fat_data[i]-np.mean(fat_data[i]))/np.std(fat_data[i])
for i in range(len(car_data)):
  car_data[i] = (car_data[i]-np.mean(car_data[i]))/np.std(car_data[i])

"""creating train and test data"""

dim = np.size(fat_data,axis=1)
train_X,train_Y = Create_data_label(fat_data,tall_data,car_data,dim,0,1000)
test_X,test_Y = Create_data_label(fat_data,tall_data,car_data,dim,1000,1300)

"""Creating model"""

def My_model(n):
  tf.config.experimental.list_logical_devices('GPU')
  tf.debugging.set_log_device_placement(True)
  with tf.device(tf.test.gpu_device_name()):
      X_input = Input(shape=(n,))
      X = Dense(3, activation='softmax', name="Fc", kernel_initializer=initializers.GlorotUniform())(X_input)
      model = Model(inputs=X_input,outputs=X, name='My_Model')
      model.compile(optimizer="Adam", loss='categorical_crossentropy', metrics=['accuracy'])
      return model

"""Fitting and testing the model"""

with tf.device(tf.test.gpu_device_name()):
  model = My_model(dim)
  model.fit(train_X,train_Y, epochs=40)
  loss,precision =  model.evaluate(train_X,train_Y)

"""Final result"""

print(f'The precision of network is {precision}.')
print(f'The loss of network is {loss}.')