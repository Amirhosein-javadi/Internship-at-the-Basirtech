# -*- coding: utf-8 -*-
"""plate_neural_network_three_layer.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14Fsrn_AdPj5e8r8If6uAGLkT3GUO9heB

Imports
"""

import tensorflow as tf
tf.config.experimental.set_memory_growth(tf.config.list_physical_devices('GPU')[0],True)
import numpy as np
from keras import initializers,Sequential
from keras.layers import Input, Dense, Activation,BatchNormalization, Flatten, Conv2D, MaxPooling2D
from keras.models import Model
from keras.preprocessing import image
from keras import metrics
from keras.metrics import SparseTopKCategoricalAccuracy 
import keras.backend as K
K.set_image_data_format("channels_last")
import glob 
import matplotlib.pyplot as plt
import cv2
from sklearn.decomposition import PCA
from keras.datasets import mnist
import random

"""Functions"""

def Create_data_label(fat,tall,car,dim,start,stop):
  New_data = cv2.vconcat([fat[start:stop,:],tall[start:stop,:],car[start:stop,:]])
  New_label = np.zeros((3*(stop-start),3))
  for i in range(stop-start):
    New_label[i,0] = 1
  for i in range(stop-start,2*(stop-start)):
    New_label[i,1] = 1
  for i in range(2*(stop-start),3*(stop-start)):
    New_label[i,2] = 1
  return New_data,New_label

def create_data(file):
  img = cv2.imread(file[0],0)
  data = np.zeros((1,img.shape[0],img.shape[1])).astype(np.float64)
  for i in range(len(file)):
    name = file[i]
    img = cv2.imread(name,0).astype(np.float64)
    img = img.reshape([1,img.shape[0],img.shape[1]])
    data = cv2.vconcat([data,img])
  data = np.delete(data, 0, 0)
  return data

"""Creating folder for images in drive"""

try:
  !rm -rf fat
  !mkdir fat
except:
  !mkdir fat

try:
  !rm -rf tall
  !mkdir tall
except:
  !mkdir tall

try:
  !rm -rf car
  !mkdir car
except:
  !mkdir car

"""Loading and resizing fat plates to size 30*60"""

Filenames1 = glob.glob('/content/drive/MyDrive/Intern/plates/fat/*')
for i in range(len(Filenames1)):
    name1 = Filenames1[i]
    img1 = cv2.imread(name1)
    resize_im1 = cv2.resize(img1,(60,30),interpolation = cv2.INTER_AREA)
    new_name1 = f'/content/fat/{i}.jpg'
    cv2.imwrite(new_name1,resize_im1)

"""Loading and resizing tall plates to size 30*60"""

Filenames2 = glob.glob('/content/drive/MyDrive/Intern/plates/tall/*')
for i in range(len(Filenames2)):
     name2 = Filenames2[i]
     img2 = cv2.imread(name2)
     resize_im2 = cv2.resize(img2,(60,30),interpolation = cv2.INTER_AREA)
     new_name2 = f'/content/tall/{i}.jpg'
     cv2.imwrite(new_name2,resize_im2)

"""Creating random images from car images"""

filename = glob.glob('/content/drive/MyDrive/Intern/car img/*')
k = 1
for i in range(len(filename)):
    name = filename[i]
    img = cv2.imread(name)
    row,col = img.shape[0],img.shape[1]
    for j in range(4):
        random_row = random.randint(100, row-100)
        random_col = random.randint(100, col-100)
        newimg = img[random_row-100:random_row+100,random_col-100:random_col+100]
        newimg = cv2.resize(newimg,(60,30),interpolation = cv2.INTER_AREA)
        new_name = f'car/{k}.jpg'
        cv2.imwrite(new_name,newimg)
        k = k + 1

"""Loading data"""

fat_plates_path = '/content/fat'
fat_image_file = glob.glob(f'{fat_plates_path}/*')
tall_plates_path = '/content/tall'
tall_image_file = glob.glob(f'{tall_plates_path}/*')
car_path = '/content/car'
car_image_file = glob.glob(f'{car_path}/*')

tall_data = create_data(tall_image_file)
fat_data = create_data(fat_image_file)
car_data = create_data(car_image_file)

"""Creating model"""

def My_model(n,m):
  tf.config.experimental.list_logical_devices('GPU')
  tf.debugging.set_log_device_placement(True)
  with tf.device(tf.test.gpu_device_name()):
      X_input = Input(shape=(n,m,1))
      X = Conv2D(32,(3,3), name="Conv", kernel_initializer=initializers.GlorotUniform())(X_input)
      X = Activation('relu')(X)
      X = MaxPooling2D((2,2), name='Max')(X)
      X = Flatten()(X)
      X = Dense(3, activation='softmax', name="Fc", kernel_initializer=initializers.GlorotUniform())(X)
      model = Model(inputs=X_input,outputs=X, name='My_Model')
      model.compile(optimizer="Adam", loss='categorical_crossentropy', metrics=['accuracy'])
      return model

"""creating train and test data"""

dim = np.size(fat_data,axis=1)
train_X,train_Y = Create_data_label(fat_data,tall_data,car_data,dim,0,1000)
test_X,test_Y = Create_data_label(fat_data,tall_data,car_data,dim,1000,1300)

"""Fitting and testing the model"""

with tf.device(tf.test.gpu_device_name()):
  model = My_model(30,60)
  model.fit(train_X,train_Y, epochs=40)
  loss,precision =  model.evaluate(train_X,train_Y)

"""Final result"""

print(f'The precision of network is {precision}.')
print(f'The loss of network is {loss}.')